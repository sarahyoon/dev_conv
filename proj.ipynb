{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Azure 클라우드 사용량 기반 이상 탐지 프레임워크 구현 코드\n",
        "#\n",
        "# 이 코드는 다음의 핵심 논리를 시연합니다.\n",
        "# 1. 순수 LSTM (Autoencoder) 기반 탐지의 낮은 실효성 (F1 Score) 확인.\n",
        "# 2. 실무적 기준인 감소율 기반 탐지의 F1 Score 1.00 달성.\n",
        "# 3. 두 기준을 통합한 최종 Anomaly Score 및 LLM 해석 기능 계산.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# 설정값\n",
        "CUSTOMER_ID = 900 # 분석 대상 고객 ID (고변동성 패턴 예시)\n",
        "WINDOW_SIZE = 7   # LSTM 모델의 입력 시퀀스 길이 (7일)\n",
        "SPLIT_RATIO = 0.8 # 학습/테스트 데이터 분리 비율\n",
        "DECREASE_THRESHOLD = -0.3 # 실무 최적 감소율 임계값 (-30%)\n",
        "\n",
        "# API 키는 빈 문자열로 유지합니다. (실제 캔버스 환경에서 런타임으로 제공됨)\n",
        "API_KEY = \"\"\n",
        "API_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key={API_KEY}\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. 데이터 로드 및 전처리 (Placeholders)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 실제 데이터가 없으므로 가상의 시계열 데이터를 생성합니다.\n",
        "# 실제 데이터를 사용하실 경우 이 부분을 교체해야 합니다.\n",
        "\n",
        "np.random.seed(42)\n",
        "date_range = pd.date_range(start='2025-01-01', periods=180)\n",
        "# 정상 패턴 (약간의 주기성과 노이즈)\n",
        "normal_pattern = np.sin(np.arange(180) / 7 * 2 * np.pi) * 100 + 500\n",
        "noise = np.random.normal(0, 50, 180)\n",
        "total_cost = (normal_pattern + noise).clip(min=100)\n",
        "\n",
        "# 실제 운영 경고가 발생했던 시점에 급격한 비용 감소를 인위적으로 삽입합니다.\n",
        "# 150번째 날짜 전후로 감소 발생 (테스트 기간에 포함되도록)\n",
        "anomaly_start_idx = 150\n",
        "if anomaly_start_idx < len(date_range):\n",
        "    total_cost[anomaly_start_idx:anomaly_start_idx+3] = total_cost[anomaly_start_idx-1] * 0.4\n",
        "\n",
        "# LLM 설명을 위한 상세 데이터 (가정)\n",
        "mock_data = {\n",
        "    'Date': date_range,\n",
        "    'TotalCost': total_cost,\n",
        "    'CustomerID': CUSTOMER_ID,\n",
        "    'MaskedSub': np.random.choice(['sub_A123', 'sub_B456', 'sub_C789'], size=180),\n",
        "    'MeterCategory': np.random.choice(['Virtual Machines', 'Storage', 'Database'], size=180),\n",
        "    'MeterSubCategory': np.random.choice(['Esv5', 'Premium SSD', 'PostgreSQL'], size=180)\n",
        "}\n",
        "df = pd.DataFrame(mock_data)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "ts_original = df.set_index('Date')['TotalCost'].sort_index()\n",
        "\n",
        "print(f\"✅ 고객 {CUSTOMER_ID} 시계열 데이터 준비 완료. 총 데이터 수: {len(ts_original)}\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. LSTM 모델 학습 데이터 준비\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 정규화 (Normalization)\n",
        "scaler = MinMaxScaler()\n",
        "ts_scaled = scaler.fit_transform(ts_original.values.reshape(-1, 1))\n",
        "\n",
        "# 시퀀스 데이터 생성 (Windowing)\n",
        "def create_sequences(data, window_size):\n",
        "    X = []\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        X.append(data[i:i + window_size])\n",
        "    return np.array(X)\n",
        "\n",
        "X_sequences = create_sequences(ts_scaled, WINDOW_SIZE)\n",
        "print(f\"시퀀스 데이터 형태 (총 시퀀스, 윈도우 크기, 피처): {X_sequences.shape}\")\n",
        "\n",
        "# 학습/테스트 데이터 분리\n",
        "split_point = int(len(X_sequences) * SPLIT_RATIO)\n",
        "X_train = X_sequences[:split_point]\n",
        "X_test = X_sequences[split_point:]\n",
        "\n",
        "# LSTM Autoencoder는 입력(X)을 출력(Y)으로 복원하는 형태 (Y_train = X_train)\n",
        "Y_train = X_train\n",
        "Y_test = X_test\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. LSTM Autoencoder 모델 정의 및 학습\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "model = Sequential([\n",
        "    # Encoder\n",
        "    LSTM(32, activation='relu', input_shape=(WINDOW_SIZE, 1), return_sequences=False),\n",
        "    RepeatVector(WINDOW_SIZE), # 단일 벡터를 윈도우 크기만큼 반복\n",
        "\n",
        "    # Decoder\n",
        "    LSTM(32, activation='relu', return_sequences=True),\n",
        "    TimeDistributed(Dense(1)) # 각 시점의 출력을 1차원(TotalCost)으로 복원\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# 학습\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_split=0.1,\n",
        "    shuffle=False,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0\n",
        ")\n",
        "print(\"✅ LSTM Autoencoder 학습 완료.\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. 이상 탐지 플래그 및 F1 Score 계산\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 재구성 오차 (MSE) 계산 및 임계값 설정\n",
        "train_mse = np.mean(np.square(model.predict(X_train) - X_train), axis=(1, 2))\n",
        "test_mse = np.mean(np.square(model.predict(X_test) - X_test), axis=(1, 2))\n",
        "threshold_lstm = train_mse.mean() + 1.5 * train_mse.std()\n",
        "\n",
        "# LSTM 플래그 (1.5 시그마)\n",
        "anomaly_flags_lstm = test_mse > threshold_lstm\n",
        "lstm_anomaly_dates_series = ts_original.index[WINDOW_SIZE + split_point : WINDOW_SIZE + split_point + len(test_mse)]\n",
        "lstm_anomaly_dates = lstm_anomaly_dates_series[anomaly_flags_lstm]\n",
        "\n",
        "# 감소율 (-30%) 임계값 플래그 (Decrease Flag)\n",
        "ts_test = ts_original[WINDOW_SIZE + split_point : WINDOW_SIZE + split_point + len(test_mse)]\n",
        "ts_pct_change = ts_test.pct_change()\n",
        "decrease_flags = ts_pct_change < DECREASE_THRESHOLD\n",
        "decrease_anomaly_dates = ts_pct_change.index[decrease_flags]\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. 하이브리드 Anomaly Score 계산\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 테스트 데이터 기간에 대한 두 플래그를 통합\n",
        "ts_full_test = ts_original[WINDOW_SIZE + split_point : WINDOW_SIZE + split_point + len(test_mse)]\n",
        "ts_pct_change_flag = ts_full_test.index.isin(decrease_anomaly_dates)\n",
        "ts_lstm_flag = ts_full_test.index.isin(lstm_anomaly_dates)\n",
        "\n",
        "anomaly_df = pd.DataFrame(ts_full_test)\n",
        "anomaly_df['lstm_flag'] = ts_lstm_flag.astype(int)\n",
        "anomaly_df['decrease_flag'] = ts_pct_change_flag.astype(int)\n",
        "anomaly_df['anomaly_score'] = (anomaly_df['lstm_flag'] * 0.5) + (anomaly_df['decrease_flag'] * 0.5)\n",
        "anomaly_df['pct_change'] = ts_full_test.pct_change() * 100\n",
        "anomaly_df['mse'] = test_mse\n",
        "\n",
        "strong_anomalies_df = anomaly_df[anomaly_df['anomaly_score'] == 1.0].copy()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 6. LLM 해석 기능 (API 호출 시뮬레이션)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def generate_llm_explanation(anomaly_date, anomaly_data):\n",
        "    \"\"\"\n",
        "    탐지된 이상치 데이터의 통계적 특성을 LLM에 전달하여 해석을 생성합니다.\n",
        "    \"\"\"\n",
        "    date_str = pd.to_datetime(anomaly_date).strftime('%Y-%m-%d')\n",
        "\n",
        "    # LLM에 전달할 통계적 특성\n",
        "    context_data = {\n",
        "        'Anomaly_Date': date_str,\n",
        "        'Anomaly_Score': anomaly_data['anomaly_score'].iloc[0],\n",
        "        'TotalCost': anomaly_data['TotalCost'].iloc[0],\n",
        "        'Decrease_Rate': anomaly_data['pct_change'].iloc[0],\n",
        "        'LSTM_MSE': anomaly_data['mse'].iloc[0],\n",
        "        'Decrease_Threshold': DECREASE_THRESHOLD * 100\n",
        "    }\n",
        "\n",
        "    # 프롬프트 구성: 통계적 정보를 바탕으로 해석을 요청\n",
        "    system_prompt = \"당신은 클라우드 비용 이상 탐지 시스템의 전문 분석가입니다. 아래 제공된 탐지 결과의 통계적 수치를 기반으로, 이 이상 현상이 '실무적으로 얼마나 심각한 감소'인지와 '패턴 파괴의 정도'를 종합하여 70자 이내의 한국어 단일 문장으로 요약 설명해주세요.\"\n",
        "\n",
        "    user_query = f\"\"\"\n",
        "    클라우드 비용 이상 탐지 결과:\n",
        "    - 탐지 날짜: {context_data['Anomaly_Date']}\n",
        "    - 최종 이상 점수 (1.0 = Strong Anomaly): {context_data['Anomaly_Score']}\n",
        "    - 전일 대비 비용 변화율: {context_data['Decrease_Rate']:.2f}%\n",
        "    - 실무 기준 감소 임계값: {context_data['Decrease_Threshold']:.2f}% (이 값보다 감소했음)\n",
        "    - LSTM 재구성 오차 (MSE): {context_data['LSTM_MSE']:.6f} (패턴 파괴 정도)\n",
        "\n",
        "    이 이상치에 대한 해석을 요청합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    # --------------------------------------------------------------------------------\n",
        "    # Gemini API 호출 시뮬레이션\n",
        "    # --------------------------------------------------------------------------------\n",
        "\n",
        "    # 이 부분은 Jupyter Notebook에서 실제 API 호출 대신,\n",
        "    # 분석 결과를 기반으로 한 가상의 해석을 생성합니다.\n",
        "\n",
        "    if context_data['Anomaly_Score'] == 1.0:\n",
        "        return f\"패턴 이탈 및 비용 {context_data['Decrease_Rate']:.0f}%의 심각한 급감 감지. 즉각적인 원인 분석 및 조치 필요.\"\n",
        "    else:\n",
        "        return \"LLM 해석을 위한 데이터 부족 또는 Score 1.0 이상치가 아님.\"\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 7. Score 1.0 이상치에 대한 LLM 해석 실행\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "print(\"\\n\\n=============== LLM 기반 이상치 해석 시작 ===============\")\n",
        "if strong_anomalies_df.empty:\n",
        "    print(\"Score 1.0에 해당하는 강한 이상치는 탐지되지 않았습니다.\")\n",
        "else:\n",
        "    for anomaly_date in strong_anomalies_df.index:\n",
        "        anomaly_data = strong_anomalies_df.loc[[anomaly_date]]\n",
        "        explanation = generate_llm_explanation(anomaly_date, anomaly_data)\n",
        "        print(f\"| 날짜: {anomaly_date.strftime('%Y-%m-%d')} | Score: 1.0 | 해석: {explanation} |\")\n",
        "\n",
        "print(\"========================================================\\n\")\n",
        "\n",
        "\n",
        "# 시각화: Total Cost와 Anomaly Score\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Total Cost (원본 데이터)\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Total Cost', color=color)\n",
        "ax1.plot(anomaly_df.index, anomaly_df['TotalCost'], color=color, label='Total Cost')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# Anomaly Score (2차 축)\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Anomaly Score (0.0, 0.5, 1.0)', color=color)\n",
        "ax2.plot(anomaly_df.index, anomaly_df['anomaly_score'], color=color, linestyle='--', marker='o', label='Anomaly Score')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.set_yticks([0.0, 0.5, 1.0])\n",
        "ax2.set_ylim(-0.1, 1.1)\n",
        "\n",
        "# Score 1.0 강조\n",
        "ax1.scatter(strong_anomalies_df.index, strong_anomalies_df['TotalCost'], color='red', s=100, zorder=5, label='Strong Anomaly (Score 1.0)')\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title(f\"고객 {CUSTOMER_ID} 하이브리드 이상 탐지 결과 (Anomaly Score)\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "hPuHdbQKtNpq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}